{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-projet - Elections\n",
    "*Basé sur Hands-on Data Preprocessing, R. Jafari, 2022*\n",
    "\n",
    "**Ce TP est noté. Merci de lire attentivement le fichier instructions.pdf avant de commencer**\n",
    "\n",
    "Nom étudiant 1: **Gombas**\n",
    "\n",
    "Prénom étudiant 1: **Owen**\n",
    "\n",
    "Nom étudiant 2: **Darmanger**\n",
    "\n",
    "Prénom étudiant 2: **David**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préambule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages standards\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List, Dict, Tuple, Callable, Any\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages spécifiques\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.path.join(\".\", \"data\")  # chemin relatif et nom du dossier \"data\"\n",
    "\n",
    "RAW_FOLDER = os.path.join(\n",
    "    DATA_FOLDER, \"raw\"\n",
    ")  # chemin du dossier raw (ne devrait pas être changé): INPUT\n",
    "\n",
    "PREPROCESSED_FOLDER = os.path.join(\n",
    "    DATA_FOLDER, \"preprocessed\"\n",
    ")  # chemin du dossier preprocessed (resultat du traitement raw): OUTPUT\n",
    "\n",
    "MEDIA_FOLDER = os.path.join(\n",
    "    DATA_FOLDER, \"media\"\n",
    ")  # chemin du dossier media pour les illustrations de mise en page des notebooks\n",
    "\n",
    "EXPLORATION_FOLDER = os.path.join(\n",
    "    DATA_FOLDER, \"exploration\"\n",
    ")  # chemin du dossier exploration pour les notebooks d'exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionnary with filename and header row\n",
    "files = {\n",
    "    \"Education.xls\": dict(header=4, dtype={\"FIPS Code\": str}),\n",
    "    \"Unemployment.xlsx\": dict(header=4, dtype={\"FIPS_Code\": str}),\n",
    "    \"PopulationEstimates.xls\": dict(header=2, dtype={\"FIPStxt\": str}),\n",
    "    \"PovertyEstimates.xls\": dict(header=4, dtype={\"FIPStxt\": str}),\n",
    "    \"countypres_2000-2020.csv\": dict(header=0, dtype={\"county_fips\": str}),\n",
    "}\n",
    "\n",
    "files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les 3 niveaux de nettoyage\n",
    "1. Les manipulation génériques (i.e., non spécifique à une application)\n",
    "2. Les restructurations pour un outil d’analyse spécifique (ex.: Tableau, Excel, Plotly, SPSS, ...)\n",
    "3. L’interprétation des valeurs et les restructurations pour un objectif d’analyse spécifique ou une problématique donnée, e.g.,\n",
    "   1. «Quelle est le prix pour une maison de 200m2 dans ce secteur?»,\n",
    "   2. «Quel accessoire recommander si l’utilisateur vient d’acheter ce téléphone portable?»\n",
    "   3. «Quel est le lien entre les facteurs sociaux et le tabagisme?»\n",
    "   \n",
    "*Source: cours*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des raw datasets et affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "for file in files:\n",
    "    basename, ext = file.split(\".\")\n",
    "\n",
    "    if ext == \"xls\" or ext == \"xlsx\":\n",
    "        df = pd.read_excel(os.path.join(RAW_FOLDER, file), header=files[file][\"header\"], dtype=files[file][\"dtype\"])\n",
    "        dfs[basename] = df\n",
    "    elif ext == \"csv\":\n",
    "        df = pd.read_csv(os.path.join(RAW_FOLDER, file), header=files[file][\"header\"], dtype=files[file][\"dtype\"])\n",
    "        dfs[basename] = df\n",
    "\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"countypres_2000-2020\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"Education\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"PovertyEstimates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"Unemployment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"PopulationEstimates\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptions de chacun des datasets à des fins de compréhension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df(df):\n",
    "    print(\"Shape:\", df.shape, end=\"\\n\\n\")\n",
    "    print(f\"{len(df.columns)} columns:\", df.columns, end=\"\\n\\n\")\n",
    "    print(\"Index:\", df.index, end=\"\\n\\n\")\n",
    "    print(\"Dtypes:\", df.dtypes, end=\"\\n\\n\")\n",
    "    print(\"Nulls:\", df.isnull().sum(), end=\"\\n\\n\")\n",
    "    print(\"Unique values:\", df.nunique(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dfs:\n",
    "    print(key)\n",
    "    describe_df(dfs[key])\n",
    "    print(\"\\n\" * 4 + \"=\" * 100 + \"\\n\" * 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compte combien de valeurs chaque colonnes possèdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dfs:\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    plt.title(key)\n",
    "    dfs[key].count().plot(kind=\"bar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dfs:\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    plt.title(key)\n",
    "    dfs[key].isnull().sum().plot(kind=\"bar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage de combien de valeurs uniques chaque colonnes possède"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dfs:\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    plt.title(key)\n",
    "    dfs[key].nunique().plot(kind=\"bar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valeurs manquantes\n",
    "Pour choisir, il faut comprendre l’objectif de l’analyse et l’impact des valeurs manquantes\n",
    "\n",
    "- (Les laisser manquantes)\n",
    "- Supprimer les lignes concernées\n",
    "- Supprimer les colonnes concernées\n",
    "- Estimer et imputer une valeur\n",
    "\n",
    "## Types de valeurs manquantes\n",
    "\n",
    "### Manquante aléatoirement\n",
    "- Pas de cause systématique (aléa(s) unique(s) ou dysfonctionnement aléatoire)\n",
    "- Elles sont inévitables\n",
    "\n",
    "### Manquante systématiquement\n",
    "- Cause systématique, potentiellement prédictible\n",
    "- On peut les éviter en changeant le processus de collecte\n",
    "\n",
    "*Source: cours*\n",
    "  \n",
    "## Traitement des valeurs manquantes et normalisation des dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_state(df: pd.DataFrame, fips_column: str = \"fips\"):\n",
    "    return df[fips_column].apply(lambda x: str(x)[-3:] == \"000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_us(df: pd.DataFrame):\n",
    "    return df[df[\"state\"] != \"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_states(df: pd.DataFrame, fips_column: str = \"fips\"):\n",
    "    return df[~is_state(df, fips_column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pr(df: pd.DataFrame):\n",
    "    return df[df[\"state\"] != \"PR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_numeric_columns(df: pd.DataFrame, method=Callable[[pd.DataFrame], Any]):\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "    df.loc[:, numeric_cols] = df[numeric_cols].fillna(method(df[numeric_cols]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df: pd.DataFrame, name: str):\n",
    "    df.to_csv(os.path.join(PREPROCESSED_FOLDER, name + \".csv\"), index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_na(df: pd.DataFrame):\n",
    "    nulls = df.isnull().sum()[df.isnull().sum() > 0].to_dict()\n",
    "    \n",
    "    if len(nulls) == 0:\n",
    "        print(\"No null values\")\n",
    "        return 0\n",
    "\n",
    "    for key, value in nulls.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # show rows with null values\n",
    "    nulls_df = df[df.isnull().any(axis=1)]\n",
    "\n",
    "    # print rows of nulls_df\n",
    "    for i in range(len(nulls_df)):\n",
    "        r = \"\"\n",
    "        for key, value in nulls_df.iloc[i].to_dict().items():\n",
    "            r += f\"{key}: {value} | \"\n",
    "        print(r)\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    df.isnull().sum().plot(kind=\"bar\")\n",
    "\n",
    "    return len(nulls_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df: pd.DataFrame, fips_column: str = \"fips\", state_column: str = \"state\"):\n",
    "    if state_column in df.columns:\n",
    "        df.rename(columns={state_column: \"state\"}, inplace=True)\n",
    "\n",
    "    if fips_column in df.columns:\n",
    "        df[fips_column] = df[fips_column].apply(lambda x: str(x).zfill(5) if x else None).astype(str)\n",
    "        df.rename(columns={fips_column: \"fips\"}, inplace=True)\n",
    "\n",
    "    df.columns = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    df.columns = [col.replace(\"-\", \"_\") for col in df.columns]\n",
    "    df.columns = [re.sub(r\"['(),]\", \"\", col) for col in df.columns]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_hard_on_fips(df: pd.DataFrame, fips: str, column: str, value: Any):\n",
    "    df.loc[df[\"fips\"] == fips, column] = value\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education\n",
    "- Manquantes car l'état en lui même ne contient pas toutes les informations, ce sont les villes dans les états qui les possèdes -> Supprimer\n",
    "- Ne possède pas l'information -> Imputer avec la moyenne de la colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df: pd.DataFrame = dfs[\"Education\"]\n",
    "education_df = normalize_columns(education_df, \"FIPS Code\")\n",
    "education_df = delete_us(education_df)\n",
    "education_df = delete_states(education_df)\n",
    "education_df = delete_pr(education_df)\n",
    "education_df = fill_numeric_columns(education_df, method=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert show_na(education_df) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(education_df, \"education\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PopulationEstimates\n",
    "- Manquantes car l'état en lui même ne contient pas toutes les informations, ce sont les villes dans les états qui les possèdes -> Supprimer\n",
    "- Ne possède pas l'information -> Dépend de la nature de la colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_estimates_df: pd.DataFrame = dfs[\"PopulationEstimates\"]\n",
    "population_estimates_df = normalize_columns(population_estimates_df, \"FIPStxt\")\n",
    "population_estimates_df = delete_us(population_estimates_df)\n",
    "population_estimates_df = delete_states(population_estimates_df)\n",
    "population_estimates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_na(population_estimates_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rural-Urban Continuum Codes (https://www.ers.usda.gov/data-products/rural-urban-continuum-codes.aspx)**  \n",
    "The 2013 Rural-Urban Continuum Codes form a classification scheme that distinguishes metropolitan counties by the population size of their metro area, and nonmetropolitan counties by degree of urbanization and adjacency to a metro area. The official Office of Management and Budget (OMB) metro and nonmetro categories have been subdivided into three metro and six nonmetro categories. Each county in the U.S., municipio in Puerto Rico, and Census Bureau-designated county-equivalent area of the Virgin Islands/other inhabited island territories of the U.S. is assigned one of the 9 codes. This scheme allows researchers to break county data into finer residential groups, beyond metro and nonmetro, particularly for the analysis of trends in nonmetro areas that are related to population density and metro influence. The Rural-Urban Continuum Codes were originally developed in 1974. They have been updated each decennial since (1983, 1993, 2003, 2013), and slightly revised in 1988. Note that the 2013 Rural-Urban Continuum Codes are not directly comparable with the codes prior to 2000 because of the new methodology used in developing the 2000 metropolitan areas.\n",
    "\n",
    "**Urban Influence Codes (https://www.ers.usda.gov/data-products/urban-influence-codes/)**  \n",
    "The 2013 Urban Influence Codes form a classification scheme that distinguishes metropolitan counties by population size of their metro area, and nonmetropolitan counties by size of the largest city or town and proximity to metro and micropolitan areas. The standard Office of Management and Budget (OMB) metro and nonmetro categories have been subdivided into two metro and 10 nonmetro categories, resulting in a 12-part county classification. This scheme was originally developed in 1993. This scheme allows researchers to break county data into finer residential groups, beyond metro and nonmetro, particularly for the analysis of trends in nonmetro areas that are related to population density and metro influence. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rural-urban_Continuum Code_2003 (source: https://seer.cancer.gov/seerstat/variables/countyattribs/Rural.Urban.Continuum.Codes.1974.1983.1993.2003.2013.pdf)**\n",
    "- FIPStxt: 2105 | State: AK -> 9\n",
    "- FIPStxt: 2195 | State: AK -> 9\n",
    "- FIPStxt: 2198 | State: AK -> 9\n",
    "- FIPStxt: 2230 | State: AK -> 9\n",
    "- FIPStxt: 2275 | State: AK -> 9\n",
    "\n",
    "**Urban_Influence_Code_2003 (source: https://www.ers.usda.gov/data-products/urban-influence-codes/)**\n",
    "- FIPStxt: 2105 | State: AK -> 10\n",
    "- FIPStxt: 2195 | State: AK -> 11\n",
    "- FIPStxt: 2198 | State: AK -> 10\n",
    "- FIPStxt: 2230 | State: AK -> 12\n",
    "- FIPStxt: 2275 | State: AK -> 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_estimates_df = replace_hard_on_fips(population_estimates_df, \"02105\", \"rural_urban_continuum_code_2003\", 9)\n",
    "population_estimates_df = replace_hard_on_fips(population_estimates_df, \"02195\", \"rural_urban_continuum_code_2003\", 9)\n",
    "population_estimates_df = replace_hard_on_fips(population_estimates_df, \"02198\", \"rural_urban_continuum_code_2003\", 9)\n",
    "population_estimates_df = replace_hard_on_fips(population_estimates_df, \"02230\", \"rural_urban_continuum_code_2003\", 9)\n",
    "population_estimates_df = replace_hard_on_fips(population_estimates_df, \"02275\", \"rural_urban_continuum_code_2003\", 9)\n",
    "\n",
    "population_estimates_df = replace_hard_on_fips(population_estimates_df, \"02105\", \"urban_influence_code_2003\", 10)\n",
    "population_estimates_df = replace_hard_on_fips(population_estimates_df, \"02195\", \"urban_influence_code_2003\", 11)\n",
    "population_estimates_df = replace_hard_on_fips(population_estimates_df, \"02198\", \"urban_influence_code_2003\", 10)\n",
    "population_estimates_df = replace_hard_on_fips(population_estimates_df, \"02230\", \"urban_influence_code_2003\", 12)\n",
    "population_estimates_df = replace_hard_on_fips(population_estimates_df, \"02275\", \"urban_influence_code_2003\", 12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Puerto Rico (PR) manque trop de valeurs, nous ne pouvons pas les imputer avec des valeurs pertinente, nous abandonnons alors le Puerto Rico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_estimates_df = delete_pr(population_estimates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert show_na(population_estimates_df) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(population_estimates_df, \"PopulationEstimates\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PovertyEstimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverity_estimates_df: pd.DataFrame = dfs[\"PovertyEstimates\"]\n",
    "poverity_estimates_df = normalize_columns(poverity_estimates_df, \"FIPStxt\", \"Stabr\")\n",
    "poverity_estimates_df = delete_us(poverity_estimates_df)\n",
    "poverity_estimates_df = delete_states(poverity_estimates_df)\n",
    "poverity_estimates_df = delete_pr(poverity_estimates_df)\n",
    "poverity_estimates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_na(poverity_estimates_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**rural_urban_continuum_code_2003 basé sur celui de 2013 (source: https://www.ers.usda.gov/data-products/rural-urban-continuum-codes.aspx)**\n",
    "- fips: 02105 | state: AK -> 10\n",
    "- fips: 02195 | state: AK -> 11\n",
    "- fips: 02198 | state: AK -> 10\n",
    "- fips: 02230 | state: AK -> 12\n",
    "- fips: 02275 | state: AK -> 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverity_estimates_df = replace_hard_on_fips(poverity_estimates_df, \"02105\", \"rural_urban_continuum_code_2003\", 10)\n",
    "poverity_estimates_df = replace_hard_on_fips(poverity_estimates_df, \"02195\", \"rural_urban_continuum_code_2003\", 11)\n",
    "poverity_estimates_df = replace_hard_on_fips(poverity_estimates_df, \"02198\", \"rural_urban_continuum_code_2003\", 10)\n",
    "poverity_estimates_df = replace_hard_on_fips(poverity_estimates_df, \"02230\", \"rural_urban_continuum_code_2003\", 12)\n",
    "poverity_estimates_df = replace_hard_on_fips(poverity_estimates_df, \"02275\", \"rural_urban_continuum_code_2003\", 12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**urban_influence_code_2003 basé sur celui de 2013 (source: https://www.ers.usda.gov/data-products/rural-urban-continuum-codes.aspx)**\n",
    "- fips: 02105 | state: AK -> 10\n",
    "- fips: 02195 | state: AK -> 11\n",
    "- fips: 02198 | state: AK -> 10\n",
    "- fips: 02230 | state: AK -> 12\n",
    "- fips: 02275 | state: AK -> 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverity_estimates_df = replace_hard_on_fips(poverity_estimates_df, \"02105\", \"urban_influence_code_2003\", 10)\n",
    "poverity_estimates_df = replace_hard_on_fips(poverity_estimates_df, \"02195\", \"urban_influence_code_2003\", 11)\n",
    "poverity_estimates_df = replace_hard_on_fips(poverity_estimates_df, \"02198\", \"urban_influence_code_2003\", 10)\n",
    "poverity_estimates_df = replace_hard_on_fips(poverity_estimates_df, \"02230\", \"urban_influence_code_2003\", 12)\n",
    "poverity_estimates_df = replace_hard_on_fips(poverity_estimates_df, \"02275\", \"urban_influence_code_2003\", 12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pov04_2019, ci90lb04_2019, ci90ub04_2019, pctpov04_2019, ci90lb04p_2019, ci90ub04p_2019**  \n",
    "Colonnes complètements vides -> suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverity_estimates_df = poverity_estimates_df.drop(columns=[\n",
    "    \"pov04_2019\",\n",
    "    \"ci90lb04_2019\",\n",
    "    \"ci90ub04_2019\",\n",
    "    \"pctpov04_2019\",\n",
    "    \"ci90lb04p_2019\",\n",
    "    \"ci90ub04p_2019\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert show_na(poverity_estimates_df) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(poverity_estimates_df, \"PovertyEstimates\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_df: pd.DataFrame = dfs[\"Unemployment\"]\n",
    "unemployment_df = normalize_columns(unemployment_df, \"FIPS_Code\")\n",
    "unemployment_df = delete_us(unemployment_df)\n",
    "unemployment_df = delete_states(unemployment_df)\n",
    "unemployment_df = delete_pr(unemployment_df)\n",
    "unemployment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_na(unemployment_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour toutes ces valeurs on peut les imputer avec la moyenne de leurs états respectifs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = unemployment_df.select_dtypes(include=np.number).columns\n",
    "unemployment_df[numeric_cols] = unemployment_df.groupby(\"state\")[numeric_cols].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "unemployment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert show_na(unemployment_df) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(unemployment_df, \"Unemployment\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## countypres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countypres_df: pd.DataFrame = dfs[\"countypres_2000-2020\"]\n",
    "countypres_df.rename(columns={\"state\": \"full_state_name\"}, inplace=True)\n",
    "countypres_df = normalize_columns(countypres_df, \"county_fips\", \"state_po\")\n",
    "countypres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_na(countypres_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_states = {\n",
    "    \"connecticut\": \"CT\",\n",
    "    \"alaska\": \"AK\",\n",
    "    \"rhode island\": \"RI\",\n",
    "    \"maine\": \"ME\",\n",
    "}\n",
    "\n",
    "countypres_df[\"state\"] = countypres_df[\"full_state_name\"].apply(lambda x: missing_states[x] if x in missing_states else x)\n",
    "\n",
    "show_na(countypres_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(countypres_df, \"countypres_2000-2020\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un fips unique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c630b349f7183e9a5f9274d889fc3e15c392ce12037771bccbc1917471fc634b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
