{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-projet - Elections\n",
    "*Basé sur Hands-on Data Preprocessing, R. Jafari, 2022*\n",
    "\n",
    "**Ce TP est noté. Merci de lire attentivement le fichier instructions.pdf avant de commencer**\n",
    "\n",
    "Nom étudiant 1: **Gombas**\n",
    "\n",
    "Prénom étudiant 1: **Owen**\n",
    "\n",
    "Nom étudiant 2: **Darmanger**\n",
    "\n",
    "Prénom étudiant 2: **David**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préambule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages standards\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List, Dict, Tuple, Callable, Any\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages spécifiques\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.path.join(\".\", \"data\")  # chemin relatif et nom du dossier \"data\"\n",
    "\n",
    "RAW_FOLDER = os.path.join(\n",
    "    DATA_FOLDER, \"raw\"\n",
    ")  # chemin du dossier raw (ne devrait pas être changé): INPUT\n",
    "\n",
    "PREPROCESSED_FOLDER = os.path.join(\n",
    "    DATA_FOLDER, \"preprocessed\"\n",
    ")  # chemin du dossier preprocessed (resultat du traitement raw): OUTPUT\n",
    "\n",
    "MEDIA_FOLDER = os.path.join(\n",
    "    DATA_FOLDER, \"media\"\n",
    ")  # chemin du dossier media pour les illustrations de mise en page des notebooks\n",
    "\n",
    "EXPLORATION_FOLDER = os.path.join(\n",
    "    DATA_FOLDER, \"exploration\"\n",
    ")  # chemin du dossier exploration pour les notebooks dexploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionnary with filename and header row\n",
    "files = glob.glob(os.path.join(PREPROCESSED_FOLDER, \"*.csv\"))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(filename, dtype={\"fips\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_na(df: pd.DataFrame):\n",
    "    nulls = df.isnull().sum()[df.isnull().sum() > 0].to_dict()\n",
    "    \n",
    "    if len(nulls) == 0:\n",
    "        print(\"No null values\")\n",
    "        return 0\n",
    "\n",
    "    for key, value in nulls.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # show rows with null values\n",
    "    nulls_df = df[df.isnull().any(axis=1)]\n",
    "\n",
    "    # print rows of nulls_df\n",
    "    for i in range(len(nulls_df)):\n",
    "        r = \"\"\n",
    "        for key, value in nulls_df.iloc[i].to_dict().items():\n",
    "            r += f\"{key}: {value} | \"\n",
    "        print(r)\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    df.isnull().sum().plot(kind=\"bar\")\n",
    "\n",
    "    return len(nulls_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = read_csv(files[2])\n",
    "datas_dfs = [read_csv(file) for file in files[:2] + files[3:]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge everything into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs_on_fips(dfs: List[pd.DataFrame]):\n",
    "    df = dfs[0]\n",
    "    for d in dfs[1:]:\n",
    "        df = pd.merge(df, d, on=\"fips\", how=\"outer\", suffixes=(\"\", \"_y\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    df = read_csv(file)\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    plt.title(f\"{file} {df.shape}\")\n",
    "\n",
    "    # Source https://datavizpyr.com/how-to-annotate-bars-in-barplot-with-matplotlib-in-python/\n",
    "    splot = sns.barplot(x=df.columns, y=df.nunique())\n",
    "    for p in splot.patches:\n",
    "        splot.annotate(\n",
    "            p.get_height(), \n",
    "            (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "            ha=\"center\",\n",
    "            va=\"center\", \n",
    "            xytext = (0, 9), \n",
    "            textcoords = \"offset points\"\n",
    "        )\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_dfs_on_fips(datas_dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop duplicated values columns\n",
    "- fips,\n",
    "- state,\n",
    "- area_name,\n",
    "- 2013_urban_influence_code,\n",
    "- percent_of_adults_with_a_high_school_diploma_only_1980,\n",
    "- percent_of_adults_completing_some_college_or_associates_degree_2000,\n",
    "- bachelors_degree_or_higher_2015_19,\n",
    "- percent_of_adults_with_less_than_a_high_school_diploma_2015_19,\n",
    "- percent_of_adults_with_a_high_school_diploma_only_2015_19,\n",
    "- percent_of_adults_completing_some_college_or_associates_degree_2015_19,\n",
    "- percent_of_adults_with_a_bachelors_degree_or_higher_2015_19,\n",
    "- **state_y**,\n",
    "- **area_name_y**,\n",
    "- urban_influence_code_2013,\n",
    "- economic_typology_2015,\n",
    "- international_mig_2019,\n",
    "- net_mig_2010,\n",
    "- net_mig_2019,\n",
    "- residual_2010,\n",
    "- residual_2011,\n",
    "- residual_2012,\n",
    "- residual_2013,\n",
    "- residual_2016,\n",
    "- residual_2019,\n",
    "- gq_estimates_2019,\n",
    "- r_birth_2019,\n",
    "- r_death_2019,\n",
    "- r_natural_inc_2019,\n",
    "- r_international_mig_2011,\n",
    "- r_international_mig_2019,\n",
    "- r_net_mig_2011,\n",
    "- r_net_mig_2012,\n",
    "- r_net_mig_2013,\n",
    "- r_net_mig_2014,\n",
    "- r_net_mig_2015,\n",
    "- r_net_mig_2016,\n",
    "- r_net_mig_2017,\n",
    "- r_net_mig_2018,\n",
    "- r_net_mig_2019,\n",
    "- **state_y**,\n",
    "- **area_name_y**,\n",
    "- urban_influence_code_2013_y,\n",
    "- ci90ub517_2019,\n",
    "- ci90ub517p_2019,\n",
    "- ci90ubinc_2019,\n",
    "- **state_y**,\n",
    "- **area_name_y**,\n",
    "- urban_influence_code_2013_y,\n",
    "- metro_2013,\n",
    "- unemployment_rate_2019,\n",
    "- unemployed_2020,\n",
    "- unemployment_rate_2020,\n",
    "- med_hh_income_percent_of_state_total_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"state_y\", \"area_name_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_na(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29161f9228c19f34a287464c1e34440c1f1ab8a7e7c0ac2d20804b112cbb89b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
